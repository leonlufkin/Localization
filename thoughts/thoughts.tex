% GO TO: /Users/leonlufkin/Library/texmf/tex/latex
%        to add custom packages to the path
\documentclass{article}
\usepackage{report}

\title{Receptive Field Localization}
\author{Leon Lufkin}
\date{\today}

\makeatletter
\let\Title\@title
\let\Author\@author
\let\Date\@date

\begin{document}

%%%%%%%%%%%
%% Model %%
%%%%%%%%%%%
\section{Model}
We begin with a general model that encapsulates many of the works we will discuss.
For an input $\mathbf{x}$, we want to predict a response $\mathbf{y}^*$.
Our prediction is a function $f_\theta$ of $\mathbf{x}$.
The function $f_\theta$ is parameterized by $\theta$.
We will consider models of the form
\begin{equation}
  \label{eq:general_model}
  f_\theta(\mathbf{x}) = y_\theta \left( \sum_i \alpha_\theta^{(i)} \phi_\theta^{(i)} (\mathbf{x}) \right).
\end{equation}
Here, $\mathbf{x}$ is an $L$-dimensional real vector and $\mathbf{y}^*$ is an $M$-dimensional real vector.
The $\phi_i$ are basis functions that map from $\R^L$ to $\R^K$, and the $\alpha_i$ are real scalars.
Additionally, the sum over $i$ need not be finite.
The coefficients $\alpha_i$ may depend on $\mathbf{x}$ and our parameters $\theta$, but we suppress the former dependence for notational simplicity. 
The function $y_\theta$ maps from $\R^K$ to $\R^M$ and is parameterized by $\theta$ as well.

We will consider a penalized mean squared error loss function
\begin{align}
  \LL(\theta) &= \frac{1}{2} \E_{\mathbf{x}, \mathbf{y}^*} \left[  \norm{ \mathbf{y}^* - f_\theta(\mathbf{x}) }_2^2  \right] + \lambda p(\{ \alpha^{(i)} \}_i, \theta).
\end{align}
Our penalty function $p$ serves to induce sparseness in the coefficients $\alpha_i$, and perhaps also regularize the parameters $\theta$.

We will show how this model encapsulates the works we are interested in understanding.

%%%%%%%%%%%%%%
%% Ingrosso %%
%%%%%%%%%%%%%%
\section{Ingrosso et al. (2022)}
The model in Ingrosso et al. (2022) sets $M = 1$, uses linear basis functions, and sets $y_\theta$ to be the mean function after applying a nonlinearity.
That is,
\begin{align}
  \sum_i \alpha_\theta^{(i)} \phi_\theta^{(i)} (\mathbf{x}) &= \Theta \mathbf{x} + b_\theta \\
  y_\theta(\mathbf{x}) &= \frac{1}{K} \bm{1}^\top \sigma(\mathbf{x}).
\end{align}
Here, $\Theta$ is a $K \times L$ matrix, $b_\theta$ is a $K$-dimensional vector, and $\sigma$ is a nonlinear function applied elementwise.
It seems that in much of their work, $b_\theta$ is fixed at $-1$ or $0$. % FIXME: when is it fixed at -1?
\hl{I still need to confirm experimentally that this does not affect the results.}

In this work, we also ignore the penalty term.
I believe that our gradient update is of the form
\begin{align}
  a
\end{align}


%%%%%%%%%%%%%%%%
%% DATA MODEL %%
%%%%%%%%%%%%%%%%
\section{Data Model}
We assume that our data is generated by the following model.
It is paramaterized by the length of the input, $L \in \N$.
It is also parameterized by a scale parameter $\xi \leq L$.
We construct data $\{ X_l \}_l \subseteq \{ 0,1 \}^L$ as follows:
\begin{enumerate}
  \item Sample integers $l^* \sim \text{Uniform}[1, L]$ (starting position) and $T \sim \text{Uniform}[1, \xi)$ (length of pulse).
  \item For $0 \leq i \leq T$, set $X_{l^* + i \pmod{L}} = 1$, and set all other $X_l$ to $0$.
  \item Return the sequence $\{ X_l \}_l$.
\end{enumerate}
Now, we derive the conditional probability $p_{11} \triangleq \PR( X_a = 1 \mid X_b = 1 )$.
For now, assume $d \triangleq b - a > 0$.
If $d \geq \xi$, then $p_{11} = 0$.
So, assume $d < \xi$.

Now, we count the number of values of $T$ that result in both $X_a$ and $X_b$ being in the pulse for a given $l^*$.
WLOG, assume $a = 0$.
For $1 \leq l^* \leq d$, the range of values for $T$ that results in both $X_a$ and $X_b$ being in the pulse is given by
\begin{align}
  L - l^* \leq T < \xi. \label{eq:case1_Trange}
\end{align}
Thus, the number of values for $T$ in this case is $\max( \xi - L + l^* , 0 )$.

For $d < l^* \leq L$, the values of $T$ that result in both $X_a$ and $X_b$ being in the pulse is given by
\begin{align}
  L - (l^* - d) \leq T < \xi. \label{eq:case2_Trange}
\end{align}
So, the number of values for $T$ in this case is $\max(\xi - (L - (l^* - d)), 0) = \max(\xi - L + l^* - d, 0)$.

Note that the first max condition is at least zero when $l^* \geq L - \xi$.
This yields a sum over $\max(L - \xi, 1) \leq l^* \leq d$.
Similarly, the second max condition is at least zero when $l^* \geq L - \xi + d$.
This yields a sum over $\max( L - \xi + d, d+1) \leq l^* \leq L$.
Note that the first term dominates in both of these new max statements when $\xi \leq L-1$.
So, let us assume this case.

Now, we want to find the total number of values of $T$ that result in both $X_a$ and $X_b$ being in the pulse.
\begin{align}
  T_1 
  &= \sum_{ L - \xi \leq l^* \leq d } (\xi - L + l^*) \label{eq:T1} \\
  T_2
  &= \sum_{ L - \xi + d \leq l^* \leq L } (\xi - L + l^* - d)
  = \sum_{ L - \xi \leq t \leq L - d } (\xi - L + t). \label{eq:T2}
\end{align}
We compute $T_1$ as,
% \begin{align*}
%   T_1
%   &= (\xi - L) (d - (L-\xi) + 1) + \frac{d(d+1)}{2} - \frac{(L-\xi)(L-\xi-1)}{2} \\
%   &= d \xi - L \xi + \frac{\xi^2}{2} + \frac{3\xi}{2} - Ld + \frac{L^2}{2} - \frac{3L}{2} + \frac{3d}{2} + 1 + \frac{d^2}{2} - d + L - \xi - 1 \\
%   &= d \xi - L \xi + \frac{\xi^2}{2} + \frac{\xi}{2} - Ld + \frac{L^2}{2} - \frac{L}{2} + \frac{d}{2} + \frac{d^2}{2}.
% \end{align*}
\begin{align*}
  T_1
  % &= (\xi - L) (d - (L-\xi) + 1) + \frac{d(d+1)}{2} - \frac{(L-\xi)(L-\xi-1)}{2} \\
  &= (\xi - L) (d - L + \xi + 1) + \frac{d(d+1)}{2} - \frac{(L-\xi)(L-\xi-1)}{2}.
\end{align*}
Next, we compute $T_2$ as,
% \begin{align*}
%   T_2
%   &= (L - (L-\xi+d) + 1) (\xi - L - d) + \frac{L(L+1)}{2} - \frac{(L-\xi+d)(L-\xi+d-1)}{2} \\
%   &= \frac{\xi^2}{2} - d\xi + \frac{\xi}{2} + \frac{d^2}{2} - \frac{d}{2}.
% \end{align*}
\begin{align*}
  T_2
  % &= ((L - d) - (L - \xi) + 1) (\xi - L) + \frac{(L-d)(L-d+1)}{2} - \frac{(L-\xi)(L-\xi-1)}{2} \\
  &= (\xi - d + 1) (\xi - L) + \frac{(L-d)(L-d+1)}{2} - \frac{(L-\xi)(L-\xi-1)}{2}.
\end{align*}
Thus, the total number of values of $T$ that result in both $X_a$ and $X_b$ being in the pulse is
% \begin{align}
%   T_1 + T_2
%   &= d \xi - L \xi + \frac{\xi^2}{2} + \frac{\xi}{2} - Ld + \frac{L^2}{2} - \frac{L}{2} + \frac{d}{2} + \frac{d^2}{2}
%   + \frac{\xi^2}{2} - d\xi + \frac{\xi}{2} + \frac{d^2}{2} - \frac{d}{2} \\
%   &= -L\xi + \xi^2 + \xi - Ld + \frac{L^2}{2} - \frac{L}{2} + d^2.
% \end{align}
\begin{align*}
  T_1 + T_2
  % &= (\xi - L) [ (d - L + \xi + 1) + (\xi - d + 1) ] + \frac{d(d+1)}{2} + \frac{(L-d)(L-d+1)}{2} - (L-\xi)(L-\xi-1) \\
  % &= (L - \xi) [(L-\xi-1) - (2\xi + 2- L)] + \frac{d(d+1)}{2} + \frac{(L-d)(L-d+1)}{2} \\
  % &= (L - \xi) (2L + \xi - 3) + \frac{d(d+1)}{2} + \frac{(L-d)(L-d+1)}{2} \\
  &= d^2 - dL + \frac{L^2}{2} + \frac{L}{2} - (L-\xi) (\xi+1)
\end{align*}
There are $\xi - 1$ possible values for $T$ and $L$ values for $l^*$.
Recall we sample $T$ and $l^*$ uniformly and independently.
Thus, the probability that $X_a = 1$ given $X_b = 1$ is
\begin{align}
  p_{11}
  &= \frac{T_1 + T_2}{(\xi - 1) L}
  % = \frac{ -L\xi + \xi^2 + \xi - Ld + \frac{L^2}{2} - \frac{L}{2} + d^2 }{ (\xi - 1) L }.
  = \frac{ d^2 - dL + \frac{L^2}{2} + \frac{L}{2} - (L-\xi) (\xi+1) }{ (\xi - 1) L }.
\end{align}
Note that we assumed $\xi \leq L-1$.
However, we can check that the above expression is still valid when $\xi = L$.
(Check Desmos. Otherwise, an exercise left to the reader.)
It also satisfies the ``sanity check'' that it is minimized at $x = \frac{L}{2}$.





\end{document}
